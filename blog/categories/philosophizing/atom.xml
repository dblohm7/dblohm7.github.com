<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: philosophizing | Aaron Klotz at Mozilla]]></title>
  <link href="http://dblohm7.ca/blog/categories/philosophizing/atom.xml" rel="self"/>
  <link href="http://dblohm7.ca/"/>
  <updated>2016-01-11T12:37:06-07:00</updated>
  <id>http://dblohm7.ca/</id>
  <author>
    <name><![CDATA[Aaron Klotz]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Throwing Code Over the Proverbial Fence]]></title>
    <link href="http://dblohm7.ca/blog/2015/08/30/throwing-code-over-the-proverbial-fence/"/>
    <updated>2015-08-30T22:00:00-06:00</updated>
    <id>http://dblohm7.ca/blog/2015/08/30/throwing-code-over-the-proverbial-fence</id>
    <content type="html"><![CDATA[<p>I was thrilled to see <a href="https://blog.mozilla.org/futurereleases/2015/07/02/what-to-look-forward-to-from-firefox/">Uncompromised Quality</a> as one of our top-line goals for
Firefox. On the other hand, it is one thing to state a goal and another to
deliver on it.</p>

<p>I&rsquo;ve worked on software performance for a long time, across a few different
employers. When it comes to quality, I&rsquo;ve seen both ends of the spectrum. If
there is one constant that I&rsquo;ve observed when it comes to software quality, it
is that the culture of the development team will either make or break the
product.</p>

<p>Disclaimer: I do not speak for Mozilla. I neither speak for my peers in the
Firefox Desktop Performance Team, nor do I speak for my management. This post
contains my personal opinions on this topic. Note that when I talk about
&ldquo;performance&rdquo; in the context of this post, I am really referring to quality
in general. Furthermore, this post should not be construed as an indictment of
quality at Mozilla &ndash; I am speaking in generalities here.</p>

<h2>What is the role of a performance team?</h2>

<p>While I think that it is important for a performance team to have the authority
to back out regressions, one task that I think that a perf team should not be
involved with is the justification as to whether or not a feature is ready for
release. When a perf team consents to this, it is effectively allowing a
shift of the burden of proof toward itself and away from the teams that are
developing new features. Unfortunately the burden of proof always takes
the <em>responsibility</em> along with it.</p>

<p>I&rsquo;ve seen this before, and it works out <strong>very</strong> poorly.</p>

<p>When teams do not hold themselves accountable for the quality of their own
features, they become complacent. Quality becomes &ldquo;somebody else&rsquo;s problem.&rdquo;
Code gets thrown over the fence by the feature teams so that they can receive
whatever incentives were promised to them for shipping. QA catches what they can,
but that is a course-grained filter. Regression tests don&rsquo;t catch anything
because they don&rsquo;t exist. The organization is threatened by the loss of users
or contracts, and eventually the perf team is called in, under the gun, to come
in and clean up the mess.</p>

<p>Coming back to Mozilla for a moment: Imagine an environment where developers
could uplift their patches with impunity, and the onus was on the release
managers to demonstrate why a patch should not be accepted into a certain
channel. This hypothetical situation is as absurd as it is unacceptable. The
same applies to performance: it must not be the perf team&rsquo;s responsibility to
prove that a feature is not ready to ship; it must be the responsibility of the
feature&rsquo;s owners to show that the feature <em>is</em> ready.</p>

<h4>So, what <em>should</em> a performance team do?</h4>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[On WebExtensions]]></title>
    <link href="http://dblohm7.ca/blog/2015/08/30/on-webextensions/"/>
    <updated>2015-08-30T02:00:00-06:00</updated>
    <id>http://dblohm7.ca/blog/2015/08/30/on-webextensions</id>
    <content type="html"><![CDATA[<p>There has been enough that has been said over the past week about <a href="https://blog.mozilla.org/addons/2015/08/21/the-future-of-developing-firefox-add-ons/">WebExtensions</a>
that I wasn&rsquo;t sure if I wanted to write this post. As usual, I can&rsquo;t seem to
help myself. Note the usual disclaimer that this is my personal opinion. Further
note that I have no involvement with WebExtensions at this time, so I write this
from the point of view of an observer.</p>

<h2>API? What API?</h2>

<p>I shall begin with the proposition that the legacy, non-jetpack
environment for addons is not an API. As ridiculous as some readers might
consider this to be, please humour me for a moment.</p>

<p>Let us go back to the acronym, &ldquo;API.&rdquo; <strong>A</strong>pplication <strong>P</strong>rogramming <strong>I</strong>nterface.
While the usage of the term &ldquo;API&rdquo; seems to have expanded over the years to encompass
just about any type of interface whatsoever, I&rsquo;d like to explore the first letter of that
acronym: <em>Application</em>.</p>

<p>An <em>Application</em> Programming Interface is a specific type of interface that is
exposed for the purposes of building applications. It typically provides a
formal abstraction layer that isolates applications from the implementation
details behind the lower tier(s) in the software stack. In the case of web
browsers, I suggest that there are two distinct types of applications:
web content, and extensions.</p>

<p>There is obviously a very well defined API for web content. On the other hand,
I would argue that Gecko&rsquo;s legacy addon environment is not an API at all! From
the point of view of an extension, there is no abstraction, limited formality,
and not necessarily an intention to be used by applications.</p>

<p>An extension is imported into Firefox with full privileges and can access whatever
it wants. Does it have access to interfaces? Yes, but are those interfaces intended
for <em>applications</em>? Some are, but many are not. The environment that Gecko
currently provides for legacy addons is analagous to an operating system running
every single application in kernel mode. Is that powerful? Absolutely! Is that
the best thing to do for maintainability and robustness? Absolutely not!</p>

<p>Somewhere a line needs to be drawn to demarcate this abstraction layer and
improve Gecko developers&#8217; ability to make improvements under the hood. Last
week&rsquo;s announcement was an invitation to addon developers to help shape that
future. Please participate and please do so constructively!</p>

<h2>WebExtensions are not Chrome Extensions</h2>

<p>When I first heard rumors about WebExtensions in Whistler, my source made it
very clear to me that the WebExtensions initiative is not about making Chrome
extensions run in Firefox. In fact, I am quite disappointed with some of the
press coverage that seems to completely miss this point.</p>

<p>Yes, WebExtensions will be implementing some APIs to be <em>source compatible</em>
with Chrome. That makes it easier to port a Chrome extension, but porting will
still be necessary. I like the Venn Diagram concept that the <a href="https://wiki.mozilla.org/WebExtensions/FAQ">WebExtensions FAQ</a>
uses: Some Chrome APIs will not be available in WebExtensions. On the other hand,
WebExtensions will be providing APIs above and beyond the Chrome API set that
will maintain Firefox&rsquo;s legacy of extensibility.</p>

<p>Please try not to think of this project as Mozilla taking functionality away.
In general I think it is safe to think of this as an opportunity to move that
same functionality to a mechanism that is more formal and abstract.</p>
]]></content>
  </entry>
  
</feed>
