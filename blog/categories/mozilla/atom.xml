<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: mozilla | Aaron Klotz at Mozilla]]></title>
  <link href="http://dblohm7.ca/blog/categories/mozilla/atom.xml" rel="self"/>
  <link href="http://dblohm7.ca/"/>
  <updated>2019-01-18T17:46:45-07:00</updated>
  <id>http://dblohm7.ca/</id>
  <author>
    <name><![CDATA[Aaron Klotz]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[2018 Roundup: Q1]]></title>
    <link href="http://dblohm7.ca/blog/2019/01/18/2018-roundup-q1/"/>
    <updated>2019-01-18T17:30:00-07:00</updated>
    <id>http://dblohm7.ca/blog/2019/01/18/2018-roundup-q1</id>
    <content type="html"><![CDATA[<p>I had a very busy 2018. So busy, in fact, that I have not been able to devote any time to actually
discussing what I worked on! I had intended to write these posts during the end of December, but a
hardware failure delayed that until the new year. Alas, here we are in 2019, and I am going to do a
series of retrospectives on last year&rsquo;s work, broken up by quarter.</p>

<p>(Links to future posts will go here)</p>

<h2>Overview</h2>

<p>The general theme of my work in 2018 was dealing with the DLL injection problem: On Windows,
third parties love to forcibly load their DLLs into other processes &ndash; web browsers in particular,
thus making Firefox a primary target.</p>

<p>Many of these libraries tend to alter Firefox processes in ways that hurt the stability and/or performance
of our code; many chemspill releases have gone out over the years to deal with these problems. While I
could rant for hours over this, the fact is that DLL injection is rampant in the ecosystem of Windows
desktop applications and is not going to disappear any time soon. In the meantime, we need to be able
to deal with it.</p>

<p>Some astute readers might be ready to send me an email or post a comment about how ignorant I am about
the new(-ish) process mitigation policies that are available in newer versions of Windows. While those
features are definitely useful, they are not panaceas:</p>

<ul>
<li>We cannot turn on the &ldquo;Extension Point Disable&rdquo; policy for users of assistive technologies; screen
readers rely heavily on DLL injection using <code>SetWindowsHookEx</code> and <code>SetWinEventHook</code>, both of which
are covered by this policy;</li>
<li>We could enable the &ldquo;Microsoft Binary Signature&rdquo; policy, however that requires us to load our own
DLLs first before enabling; once that happens, it is often already too late: other DLLs have already
injected themselves by the time we are able to activate this policy. (Note that this could easily be
solved if this policy were augmented to also permit loading of any DLL signed by the same organization
as that of the process&rsquo;s executable binary, but Microsoft seems to be unwilling to do this.)</li>
<li>The above mitigations are not universally available. They do not help us on Windows 7.</li>
</ul>


<p>For me, Q1 2018 was all about gathering better data about injected DLLs.</p>

<h2>Learning More About DLLs Injected into Firefox</h2>

<p>One of our major pain points over the years of dealing with injected DLLs has been that the vendor of
the DLL is not always apparent to us. In general, our crash reports and telemetry pings only include
the leaf name of the various DLLs on a user&rsquo;s system. This is intentional on our part: we want to
preserve user privacy. On the other hand, this severely limits our ability to determine which party
is responsible for a particular DLL.</p>

<p>One avenue for obtaining this information is to look at any digital signature that is embedded in the
DLL. By examining the certificate that was used to sign the binary, we can extract the organization
of the cert&rsquo;s owner and include that with our crash reports and telemetry.</p>

<p>In <a title="Include authenticode cert information with crash reports" href="https://bugzilla.mozilla.org/show_bug.cgi?id=1430857">bug 1430857</a> I wrote a bunch of code that enables us to extract that information from signed
binaries using the Windows Authenticode APIs. Originally, in that bug, all of that signature extraction
work happened from within the browser itself, while it was running: It would gather the cert information
on a background thread while the browser was running, and include those annotations in a subsequent
crash dump, should such a thing occur.</p>

<p>After some reflection, I realized that I was not gathering annotations in the right place. As an example,
what if an injected DLL were to trigger a crash before the background thread had a chance to grab
that DLL&rsquo;s cert information?</p>

<p>I realized that the best place to gather this information was in a post-processing step after the
crash dump had been generated, and in fact we already had the right mechanism for doing so: the
<code>minidump-analyzer</code> program was already doing post-processing on Firefox crash dumps before sending
them back to Mozilla. I moved the signature extraction and crash annotation code out of Gecko and
into the analyzer in <a title="Cert annotation performance and reliability improvements" href="https://bugzilla.mozilla.org/show_bug.cgi?id=1436845">bug 1436845</a>.</p>

<p>(As an aside, while working on the <code>minidump-analyzer</code>, I found some problems with how it handled
command line arguments: it was assuming that <code>main</code> passes its <code>argv</code> as UTF-8, which is not true on
Windows. I fixed those issues in <a title="Minidump analyzer assuming utf-8 command-line arguments on Windows" href="https://bugzilla.mozilla.org/show_bug.cgi?id=1437156">bug 1437156</a>.)</p>

<p>In <a title="Add module cert info to modules ping" href="https://bugzilla.mozilla.org/show_bug.cgi?id=1434489">bug 1434489</a> I also ended up adding this information to the &ldquo;modules ping&rdquo; that we have in
telemetry; IIRC this ping is only sent weekly. When the modules ping is requested, we gather the
module cert info asynchronously on a background thread.</p>

<p>Finally, I had to modify Socorro (the back-end for <a href="https://crash-stats.mozilla.com">crash-stats</a>) to
be able to understand the signature annotations and be able to display them via <a title="Add module cert info to crash report "Modules" tab" href="https://bugzilla.mozilla.org/show_bug.cgi?id=1434495">bug 1434495</a>. This
required two commits: one to modify the Socorro stackwalker to merge the module signature information
into the full crash report, and another to add a &ldquo;Signed By&rdquo; column to every report&rsquo;s &ldquo;Modules&rdquo; tab to
display the signature information (Note that this column is only present when at least one module in
a particular crash report contains signature information).</p>

<p>The end result was very satisfying: Most of the injected DLLs in our Windows crash reports are signed,
so it is now much easier to identify their vendors!</p>

<p>This project was very satisifying for me in many ways: First of all, surfacing this information was an
itch that I had been wanting to scratch for quite some time. Secondly, this really was a &ldquo;full stack&rdquo;
project, touching everything from extracting signature info from binaries using C++, all the way up to
writing some back-end code in Python and a little touch of front-end stuff to surface the data in the
web app.</p>

<p>Note that, while this project focused on Windows because of the severity of the library injection
problem on that platform, it would be easy enough to reuse most of this code for macOS builds as well;
the only major work for the latter case would be for extracting signature information from a dylib.
This is not currently a priority for us, though.</p>

<p>Thanks for reading! Coming up in Q2: Refactoring the Windows DLL Interceptor!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Legacy Firefox Extensions and "Userspace"]]></title>
    <link href="http://dblohm7.ca/blog/2017/11/16/legacy-firefox-extensions-and-userspace/"/>
    <updated>2017-11-16T13:30:00-07:00</updated>
    <id>http://dblohm7.ca/blog/2017/11/16/legacy-firefox-extensions-and-userspace</id>
    <content type="html"><![CDATA[<p>This week&rsquo;s release of Firefox Quantum has prompted all kinds of feedback, both
positive and negative. That is not surprising to anybody &ndash; any software that
has a large number of users is going to be a topic for discussion, especially
when the release in question is undoubtedly a watershed.</p>

<p>While I have <a href="http://dblohm7.ca/blog/2015/08/30/on-webextensions/">previously</a>
blogged about the transition to WebExtensions, now that we have actually passed
through the cutoff for legacy extensions, I have decided to add some new
commentary on the subject.</p>

<p>One analogy that has been used in the discussion of the extension ecosystem is
that of kernelspace and userspace. The crux of the analogy is that Gecko is
equivalent to an operating system kernel, and thus extensions are the user-mode
programs that run atop that kernel. The argument then follows that Mozilla&rsquo;s
deprecation and removal of legacy extension capabilities is akin to &ldquo;breaking&rdquo;
userspace. [<em>Some people who say this are using the same tone as Linus does
whenever he eviscerates Linux developers who break userspace, which is neither
productive nor welcomed by anyone, but I digress.</em>] Unfortunately, that analogy
simply does not map to the legacy extension model.</p>

<h2>Legacy Extensions as Kernel Modules</h2>

<p>The most significant problem with the userspace analogy is that legacy extensions
effectively meld with Gecko and become part of Gecko itself. If we accept the
premise that Gecko is like a monolithic OS kernel, then we must also accept that
the analogical equivalent of loading arbitrary code into that kernel, is the
kernel module. Such components are loaded into the kernel and effectively become
part of it. Their code runs with full privileges. They break whenever
significant changes are made to the kernel itself.</p>

<p>Sound familiar?</p>

<p>Legacy extensions were akin to kernel modules. When there is no abstraction,
there can be no such thing as userspace. This is precisely the problem that
WebExtensions solves!</p>

<h2>Building Out a Legacy API</h2>

<p>Maybe somebody out there is thinking, &ldquo;well what if you took all the APIs that
legacy extensions used, turned that into a &lsquo;userspace,&rsquo; and then just left that
part alone?&rdquo;</p>

<p>Which APIs? Where do we draw the line? Do we check the code coverage for every
legacy addon in AMO and use that to determine what to include?</p>

<p>Remember, there was no abstraction; installed legacy addons are fused to Gecko.
If we pledge not to touch anything that legacy addons might touch, then we
cannot touch anything at all.</p>

<p>Where do we go from here? Freeze an old version of Gecko and host an entire copy
of it inside web content? Compile it to WebAssembly? [<em>Oh God, what have I done?</em>]</p>

<p>If <em>that&rsquo;s</em> not a maintenance burden, I don&rsquo;t know what is!</p>

<h2>A Kernel Analogy for WebExtensions</h2>

<p>Another problem with the legacy-extensions-as-userspace analogy is that it leaves
awkward room for web content, whose API is abstract and well-defined. I do not
think that it is appropriate to consider web content to be equivalent to a
sandboxed application, as sandboxed applications use the same (albeit restricted)
API as normal applications. I would suggest that the presence of WebExtensions
gives us a better kernel analogy:</p>

<ul>
<li>Gecko is the kernel;</li>
<li>WebExtensions are privileged user applications;</li>
<li>Web content runs as unprivileged user applications.</li>
</ul>


<h2>In Conclusion</h2>

<p>Declaring that legacy extensions are userspace does not make them so. The way that
the technology actually worked defies the abstract model that the analogy
attempts to impose upon it. On the other hand, we can use the failure of that
analogy to explain why WebExtensions are important and construct an extension
ecosystem that <em>does</em> fit with that analogy.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Win32 Gotchas]]></title>
    <link href="http://dblohm7.ca/blog/2017/07/17/win32-gotchas/"/>
    <updated>2017-07-17T12:00:00-06:00</updated>
    <id>http://dblohm7.ca/blog/2017/07/17/win32-gotchas</id>
    <content type="html"><![CDATA[<p>For the second time since I have been at Mozilla I have encountered a situation
where hooks are called for notifications of a newly created window, but that
window has not yet been initialized properly, causing the hooks to behave badly.</p>

<p>The first time was inside our window neutering code in IPC, while the second
time was in our accessibility code.</p>

<p>Every time I have seen this, there is code that follows this pattern:</p>

<pre><code class="c++">HWND hwnd = CreateWindowEx(/* ... */);
if (hwnd) {
  // Do some follow-up initialization to hwnd (Using SetProp as an example):
  SetProp(hwnd, "Foo", bar);
}
</code></pre>

<p>This seems innocuous enough, right?</p>

<p>The problem is that <code>CreateWindowEx</code> calls hooks. If those hooks then try to do
something like <code>GetProp(hwnd, "Foo")</code>, that call is going to fail because the
&ldquo;Foo&rdquo; prop has not yet been set.</p>

<p>The key takeaway from this is that, if you are creating a new window, you must
do any follow-up initialization from within your window proc&rsquo;s <code>WM_CREATE</code>
handler. This will guarantee that your window&rsquo;s initialization will have
completed before any hooks are called.</p>

<p>You might be thinking, &ldquo;But I don&rsquo;t set any hooks!&rdquo; While this may be true, you
must not forget about hooks set by third-party code.</p>

<p>&ldquo;But those hooks won&rsquo;t know anything about my program&rsquo;s internals, right?&rdquo;</p>

<p>Perhaps, perhaps not. But when those hooks fire, they give third-party software
the opportunity to run. In some cases, those hooks might even cause the thread
to <em>reenter your own code</em>. Your window had better be completely initialized
when this happens!</p>

<p>In the case of my latest discovery of this issue in <a title="Window emulation needs to SetProp inside WM_CREATE" href="https://bugzilla.mozilla.org/show_bug.cgi?id=1380471">bug 1380471</a>, I made it
possible to use a C++11 lambda to simplify this pattern.</p>

<p><a href="https://msdn.microsoft.com/en-us/library/windows/desktop/ms632680.aspx"><code>CreateWindowEx</code></a>
accepts a <code>lpParam</code> parameter which is then passed to the <code>WM_CREATE</code> handler
as the <code>lpCreateParams</code> member of a <a href="https://msdn.microsoft.com/en-us/library/windows/desktop/ms632603.aspx"><code>CREATESTRUCT</code></a>.</p>

<p>By setting <code>lpParam</code> to a pointer to a <code>std::function&lt;void(HWND)&gt;</code>, we may then
supply any callable that we wish for follow-up window initialization.</p>

<p>Using the previous code sample as a baseline, this allows me to revise the code
to safely set a property like this:</p>

<pre><code class="c++">std::function&lt;void(HWND)&gt; onCreate([](HWND aHwnd) -&gt; void {
  SetProp(aHwnd, "Foo", bar);
});

HWND hwnd = CreateWindowEx(/* ... */, &amp;onCreate);
// At this point is already too late to further initialize hwnd!
</code></pre>

<p>Note that since <code>lpParam</code> is always passed during <code>WM_CREATE</code>, which always fires
before <code>CreateWindowEx</code> returns, it is safe for <code>onCreate</code> to live on the stack.</p>

<p>I liked this solution for the a11y case because it preserved the locality of
the initialization code within the function that called <code>CreateWindowEx</code>; the
window proc for this window is implemented in another source file and the
follow-up initialization depends on the context surrounding the <code>CreateWindowEx</code>
call.</p>

<p>Speaking of window procs, here is how that window&rsquo;s <code>WM_CREATE</code> handler invokes
the callable:</p>

<pre><code class="c++">switch (uMsg) {
  case WM_CREATE: {
    auto createStruct = reinterpret_cast&lt;CREATESTRUCT*&gt;(lParam);
    auto createProc = reinterpret_cast&lt;std::function&lt;void(HWND)&gt;*&gt;(
      createStruct-&gt;lpCreateParams);

    if (createProc &amp;&amp; *createProc) {
      (*createProc)(hwnd);
    }

    return 0;
  }
  // ...
</code></pre>

<p><strong>TL;DR:</strong> If you see a pattern where further initialization work is being done
on an <code>HWND</code> after a <code>CreateWindowEx</code> call, move that initialization code to your
window&rsquo;s <code>WM_CREATE</code> handler instead.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Why I prefer using CRITICAL_SECTIONs for mutexes in Windows Nightly builds]]></title>
    <link href="http://dblohm7.ca/blog/2017/06/12/why-i-prefer-using-critical-sections-for-mutexes-in-windows-nightly-builds/"/>
    <updated>2017-06-12T15:50:43-06:00</updated>
    <id>http://dblohm7.ca/blog/2017/06/12/why-i-prefer-using-critical-sections-for-mutexes-in-windows-nightly-builds</id>
    <content type="html"><![CDATA[<p>In the past I have argued that our Nightly builds, both debug and release, should
use <code>CRITICAL_SECTION</code>s (with full debug info) for our implementation of
<code>mozilla::Mutex</code>. I&rsquo;d like to illustrate some reasons why this is so useful.</p>

<h2>They enable more utility in WinDbg extensions</h2>

<p>Every time you initialize a <code>CRITICAL_SECTION</code>, Windows inserts the CS&rsquo;s
debug info into a process-wide linked list. This enables their discovery by
the Windows debugging engine, and makes the <code>!cs</code>, <code>!critsec</code>, and <code>!locks</code>
commands more useful.</p>

<h2>They enable profiling of their initialization and acquisition</h2>

<p>When the &ldquo;Create user mode stack trace database&rdquo; gflag is enabled, Windows
records the call stack of the thread that called <code>InitializeCriticalSection</code>
on that CS. Windows also records the call stack of the owning thread once
it has acquired the CS. This can be very useful for debugging deadlocks.</p>

<h2>They track their contention counts</h2>

<p>Since every CS has been placed in a process-wide linked list, we may now ask
the debugger to dump statistics about every live CS in the process. In
particular, we can ask the debugger to output the contention counts for each
CS in the process. After running a workload against Nightly, we may then take
the contention output, sort it descendingly, and be able to determine which
<code>CRITICAL_SECTION</code>s are the most contended in the process.</p>

<p>We may then want to more closely inspect the hottest CSes to determine whether
there is anything that we can do to reduce contention and all of the extra
context switching that entails.</p>

<h2>In Summary</h2>

<p>When we use <code>SRWLOCK</code>s or initialize our <code>CRITICAL_SECTION</code>s with the
<code>CRITICAL_SECTION_NO_DEBUG_INFO</code> flag, we are denying ourselves access to this
information. That&rsquo;s fine on release builds, but on Nightly I think it is worth
having around. While I realize that most Mozilla developers have not used this
until now (otherwise I would not be writing this blog post), this rich debugger
info is one of those things that you do not miss until you do not have it.</p>

<p>For further reading about critical section debug info, check out
<a href="https://web.archive.org/web/20150419055323/https://msdn.microsoft.com/en-us/magazine/cc164040.aspx">this</a>
archived article from MSDN Magazine.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Asynchronous Plugin Initialization: Requiem]]></title>
    <link href="http://dblohm7.ca/blog/2017/04/07/asynchronous-plugin-initialization-requiem/"/>
    <updated>2017-04-07T15:00:00-06:00</updated>
    <id>http://dblohm7.ca/blog/2017/04/07/asynchronous-plugin-initialization-requiem</id>
    <content type="html"><![CDATA[<p>My colleague <del>bsmedberg</del> njn is going to be removing asynchronous plugin
initialization in <a title="Remove support for async plugin init" href="https://bugzilla.mozilla.org/show_bug.cgi?id=1352575">bug 1352575</a>. Sadly the feature never became solid enough
to remain enabled on release, so we cut our losses and cancelled the project
early in 2016. Now that code is just a bunch of dead weight. With the
deprecation of non-Flash NPAPI plugins in Firefox 52, our developers are now
working on simplifying the remaining NPAPI code as much as possible.</p>

<p>Obviously the removal of that code does not prevent me from discussing some of
the more interesting facets of that work.</p>

<p>Today I am going to talk about how async plugin init worked when web content
attempted to access a property on a plugin&rsquo;s scriptable object, when that
plugin had not yet completed its asynchronous initialization.</p>

<p>As <a href="https://developer.mozilla.org/en-US/docs/Plugins/Guide/Scripting_plugins">described on MDN</a>,
the DOM queries a plugin for scriptability by calling <code>NPP_GetValue</code> with the
<code>NPPVpluginScriptableNPObject</code> constant. With async plugin init, we did not
return the true NPAPI scriptable object back to the DOM. Instead we returned
a surrogate object. This meant that we did not need to synchronously wait for
the plugin to initialize before returning a result back to the DOM.</p>

<p>If the DOM subsequently called into that surrogate object, the surrogate would
be forced to synchronize with the plugin. There was a limit on how much fakery
the async surrogate could do once the DOM needed a definitive answer &ndash; after
all, the NPAPI itself is entirely synchronous. While you may question whether
the asynchronous surrogate actually bought us any responsiveness, performance
profiles and measurements that I took at the time did indeed demonstrate that
the asynchronous surrogate did buy us enough additional concurrency to make it
worthwhile. A good number of plugin instantiations were able to complete in
time before the DOM had made a single invocation on the surrogate.</p>

<p>Once the surrogate object had synchronized with the plugin, it would then mostly
act as a pass-through to the plugin&rsquo;s real NPAPI scriptable object, with one
notable exception: property accesses.</p>

<p>The reason for this is not necessarily obvious, so allow me to elaborate:</p>

<p>The DOM usually sets up a scriptable object as follows:</p>

<pre><samp>
this.__proto__.__proto__.__proto__
</samp></pre>


<ul>
<li>Where <code>this</code> is the WebIDL object (ie, content&rsquo;s <code>&lt;embed&gt;</code> element);</li>
<li>Whose prototype is the NPAPI scriptable object;</li>
<li>Whose prototype is the shared WebIDL prototype;</li>
<li>Whose prototype is <code>Object.prototype</code>.</li>
</ul>


<p>NPAPI is reentrant (some might say <em>insanely</em> reentrant). It is possible (and
indeed common) for a plugin to set properties on the WebIDL object from within
the plugin&rsquo;s <code>NPP_New</code>.</p>

<p>Suppose that the DOM tries to access a property on the plugin&rsquo;s WebIDL object
that is normally set by the plugin&rsquo;s <code>NPP_New</code>. In the asynchronous case, the
plugin&rsquo;s initialization might still be in progress, so that property might not
yet exist.</p>

<p>In the case where the property does not yet exist on the WebIDL object, JavaScript
fails to retrieve an &ldquo;own&rdquo; property. It then moves on to the first prototype
and attempts to resolve the property on that. As outlined above, this prototype
would actually be the async surrogate. The async surrogate would then be in a
situation where it must absolutely produce a definitive result, so this would
trigger synchronization with the plugin. At this point the plugin would be
guaranteed to have finished initializing.</p>

<p>Now we have a problem: JS was already examining the NPAPI scriptable object when
it blocked to synchronize with the plugin. Meanwhile, the plugin went ahead and
set properties (including the one that we&rsquo;re interested in) on the WebIDL object.
By the time that JS execution resumes, it would already be looking too far up the
prototype chain to see those new properties!</p>

<p>The surrogate needed to be aware of this when it synchronized with the plugin
during a property access. If the plugin had already completed its initialization
(thus rendering synchronization unnecessary), the surrogate would simply pass the
property access on to the real NPAPI scriptable object. On the other hand, if a
synchronization was performed, the surrogate would first retry the WebIDL object
by querying for the WebIDL object&rsquo;s &ldquo;own&rdquo; properties, and return the own property
if it now existed. If no own property existed on the WebIDL object, then the
surrogate would revert to its &ldquo;pass through all the things&rdquo; behaviour.</p>

<p>If I hadn&rsquo;t made the asynchronous surrogate scriptable object do that, we would
have ended up with a strange situation where the DOM&rsquo;s initial property access
on an embed could fail non-deterministically during page load.</p>

<p>That&rsquo;s enough chatter for today. I enjoy blogging about my crazy hacks that make
the impossible, umm&hellip; possible, so maybe I&rsquo;ll write some more of these in the
future.</p>
]]></content>
  </entry>
  
</feed>
